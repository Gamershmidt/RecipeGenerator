[2024-10-01T18:00:38.782+0300] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-10-01T18:00:38.804+0300] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-10-01T18:00:38.804+0300] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-10-01T18:00:38.807+0300] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 13082
[2024-10-01T18:00:38.808+0300] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-10-01T18:00:38.810+0300] {settings.py:63} INFO - Configured default timezone UTC
[2024-10-01T18:00:38.812+0300] {scheduler_job_runner.py:1870} INFO - Marked 1 SchedulerJob instances as failed
[2024-10-01T18:00:38.821+0300] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-10-01T18:03:13.915+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:00:00+00:00, run_after=2024-10-01 15:05:00+00:00
Dag run  in running state
Dag information Queued at: 2024-10-01 15:03:13.909075+00:00 hash info: 8315c6d8b96e65e91b8160d8ac3af7cc
[2024-10-01T18:03:13.941+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>
[2024-10-01T18:03:13.941+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:03:13.941+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>
[2024-10-01T18:03:13.942+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:03:13.942+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T14:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:03:13.942+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T14:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:03:13.944+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T14:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:03:14.819+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:03:14.905+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:03:14.905+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:03:14.911+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:03:14.930+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:03:14.993+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:03:15.002+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:03:15.024+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:03:16.258+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T14:55:00+00:00', try_number=1, map_index=-1)
[2024-10-01T18:03:16.262+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T14:55:00+00:00, map_index=-1, run_start_date=2024-10-01 15:03:15.047706+00:00, run_end_date=2024-10-01 15:03:15.955957+00:00, run_duration=0.908251, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:03:13.941943+00:00, queued_by_job_id=21, pid=13696
Dag run  in running state
Dag information Queued at: 2024-10-01 15:03:13.443530+00:00 hash info: 8315c6d8b96e65e91b8160d8ac3af7cc
[2024-10-01T18:03:16.400+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>
[2024-10-01T18:03:16.400+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:03:16.400+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>
[2024-10-01T18:03:16.401+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:03:16.401+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:03:13.431464+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:03:16.401+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:03:13.431464+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:03:16.403+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:03:13.431464+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:03:17.246+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:03:17.322+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:03:17.322+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:03:17.328+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:03:17.346+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:03:17.403+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:03:17.410+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:03:17.424+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:03:18.335+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:03:13.431464+00:00', try_number=1, map_index=-1)
[2024-10-01T18:03:18.338+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=manual__2024-10-01T15:03:13.431464+00:00, map_index=-1, run_start_date=2024-10-01 15:03:17.447978+00:00, run_end_date=2024-10-01 15:03:18.094242+00:00, run_duration=0.646264, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:03:16.401172+00:00, queued_by_job_id=21, pid=13749
[2024-10-01T18:05:01.124+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:05:00+00:00, run_after=2024-10-01 15:10:00+00:00
Dag run  in running state
Dag information Queued at: 2024-10-01 15:05:01.121930+00:00 hash info: 8315c6d8b96e65e91b8160d8ac3af7cc
[2024-10-01T18:05:01.148+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:00:00+00:00 [scheduled]>
[2024-10-01T18:05:01.149+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:05:01.149+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:00:00+00:00 [scheduled]>
[2024-10-01T18:05:01.149+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:05:01.150+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:05:01.150+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:05:01.152+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:05:01.997+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:05:02.074+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:05:02.074+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:05:02.080+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:05:02.099+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:05:02.158+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:05:02.165+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:05:02.180+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:00:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:05:03.100+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:00:00+00:00', try_number=1, map_index=-1)
[2024-10-01T18:05:03.102+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T15:00:00+00:00, map_index=-1, run_start_date=2024-10-01 15:05:02.206311+00:00, run_end_date=2024-10-01 15:05:02.846030+00:00, run_duration=0.639719, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:05:01.149601+00:00, queued_by_job_id=21, pid=13967
[2024-10-01T18:05:38.974+0300] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-10-01T18:08:16.639+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>
[2024-10-01T18:08:16.640+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:08:16.640+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>
[2024-10-01T18:08:16.640+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:08:16.641+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T14:55:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:08:16.641+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T14:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:08:16.643+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T14:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:08:17.508+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:08:17.587+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:08:17.588+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:08:17.594+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:08:17.612+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:08:17.671+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:08:17.679+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:08:17.694+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T14:55:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:08:18.664+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T14:55:00+00:00', try_number=2, map_index=-1)
[2024-10-01T18:08:18.666+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T14:55:00+00:00, map_index=-1, run_start_date=2024-10-01 15:08:17.719370+00:00, run_end_date=2024-10-01 15:08:18.388054+00:00, run_duration=0.668684, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:08:16.640500+00:00, queued_by_job_id=21, pid=14343
[2024-10-01T18:08:18.819+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>
[2024-10-01T18:08:18.820+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:08:18.820+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>
[2024-10-01T18:08:18.820+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:08:18.821+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:03:13.431464+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:08:18.821+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:03:13.431464+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:08:18.825+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:03:13.431464+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:08:19.700+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:08:19.780+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:08:19.780+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:08:19.786+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:08:19.804+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:08:19.863+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:08:19.870+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:08:19.884+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:03:13.431464+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:08:20.800+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:03:13.431464+00:00', try_number=2, map_index=-1)
[2024-10-01T18:08:20.803+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=manual__2024-10-01T15:03:13.431464+00:00, map_index=-1, run_start_date=2024-10-01 15:08:19.903100+00:00, run_end_date=2024-10-01 15:08:20.528556+00:00, run_duration=0.625456, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:08:18.820548+00:00, queued_by_job_id=21, pid=14395
[2024-10-01T18:08:20.936+0300] {dagrun.py:823} ERROR - Marking run <DagRun mlopspmdl @ 2024-10-01 14:55:00+00:00: scheduled__2024-10-01T14:55:00+00:00, state:running, queued_at: 2024-10-01 15:03:13.909075+00:00. externally triggered: False> failed
Dag run  in failure state
Dag information:mlopspmdl Run id: scheduled__2024-10-01T14:55:00+00:00 external trigger: False
Failed with message: task_failure
[2024-10-01T18:08:20.936+0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=mlopspmdl, execution_date=2024-10-01 14:55:00+00:00, run_id=scheduled__2024-10-01T14:55:00+00:00, run_start_date=2024-10-01 15:03:13.922245+00:00, run_end_date=2024-10-01 15:08:20.936800+00:00, run_duration=307.014555, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-01 14:55:00+00:00, data_interval_end=2024-10-01 15:00:00+00:00, dag_hash=8315c6d8b96e65e91b8160d8ac3af7cc
[2024-10-01T18:08:20.940+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:00:00+00:00, run_after=2024-10-01 15:05:00+00:00
[2024-10-01T18:08:22.084+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:05:00+00:00, run_after=2024-10-01 15:10:00+00:00
[2024-10-01T18:08:22.096+0300] {dagrun.py:823} ERROR - Marking run <DagRun mlopspmdl @ 2024-10-01 15:03:13.431464+00:00: manual__2024-10-01T15:03:13.431464+00:00, state:running, queued_at: 2024-10-01 15:03:13.443530+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:mlopspmdl Run id: manual__2024-10-01T15:03:13.431464+00:00 external trigger: True
Failed with message: task_failure
[2024-10-01T18:08:22.096+0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=mlopspmdl, execution_date=2024-10-01 15:03:13.431464+00:00, run_id=manual__2024-10-01T15:03:13.431464+00:00, run_start_date=2024-10-01 15:03:16.386435+00:00, run_end_date=2024-10-01 15:08:22.096617+00:00, run_duration=305.710182, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-10-01 14:55:00+00:00, data_interval_end=2024-10-01 15:00:00+00:00, dag_hash=8315c6d8b96e65e91b8160d8ac3af7cc
[2024-10-01T18:10:39.123+0300] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-10-01T18:12:05.641+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:10:00+00:00, run_after=2024-10-01 15:15:00+00:00
Dag run  in running state
Dag information Queued at: 2024-10-01 15:12:05.638693+00:00 hash info: cdfac01871f4e4050b9a45083cfefadb
Dag run  in running state
Dag information Queued at: 2024-10-01 15:12:04.995739+00:00 hash info: cdfac01871f4e4050b9a45083cfefadb
[2024-10-01T18:12:05.663+0300] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>
[2024-10-01T18:12:05.663+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:12:05.663+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 1/16 running and queued tasks
[2024-10-01T18:12:05.663+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>
[2024-10-01T18:12:05.664+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>, <TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:12:05.664+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:12:05.664+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:12:05.664+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:12:04.978301+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:12:05.664+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:12:04.978301+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:12:05.666+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:12:06.548+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:12:06.626+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:12:06.626+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:12:06.632+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:12:06.650+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:12:06.707+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:12:06.715+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:12:06.729+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:12:07.097+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:12:04.978301+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:12:07.962+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:12:08.040+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:12:08.040+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:12:08.045+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:12:08.063+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:12:08.121+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:12:08.128+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:12:08.142+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:12:08.514+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:05:00+00:00', try_number=1, map_index=-1)
[2024-10-01T18:12:08.514+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:12:04.978301+00:00', try_number=1, map_index=-1)
[2024-10-01T18:12:08.518+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=manual__2024-10-01T15:12:04.978301+00:00, map_index=-1, run_start_date=2024-10-01 15:12:08.166477+00:00, run_end_date=2024-10-01 15:12:08.238953+00:00, run_duration=0.072476, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:12:05.663805+00:00, queued_by_job_id=21, pid=15132
[2024-10-01T18:12:08.518+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T15:05:00+00:00, map_index=-1, run_start_date=2024-10-01 15:12:06.754424+00:00, run_end_date=2024-10-01 15:12:06.826552+00:00, run_duration=0.072128, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:12:05.663805+00:00, queued_by_job_id=21, pid=15112
[2024-10-01T18:15:01.571+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:15:00+00:00, run_after=2024-10-01 15:20:00+00:00
Dag run  in running state
Dag information Queued at: 2024-10-01 15:15:01.568892+00:00 hash info: cdfac01871f4e4050b9a45083cfefadb
[2024-10-01T18:15:01.593+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:10:00+00:00 [scheduled]>
[2024-10-01T18:15:01.593+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:15:01.593+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:10:00+00:00 [scheduled]>
[2024-10-01T18:15:01.594+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:15:01.594+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:15:01.594+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:15:01.596+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:15:02.462+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:15:02.541+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:15:02.541+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:15:02.547+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:15:02.566+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:15:02.627+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:15:02.635+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:15:02.652+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:10:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:15:03.050+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:10:00+00:00', try_number=1, map_index=-1)
[2024-10-01T18:15:03.053+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T15:10:00+00:00, map_index=-1, run_start_date=2024-10-01 15:15:02.679642+00:00, run_end_date=2024-10-01 15:15:02.756223+00:00, run_duration=0.076581, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:15:01.594133+00:00, queued_by_job_id=21, pid=15658
[2024-10-01T18:15:39.282+0300] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-10-01T18:17:07.298+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>
[2024-10-01T18:17:07.298+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:17:07.298+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>
[2024-10-01T18:17:07.299+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:17:07.299+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:05:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:17:07.299+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:17:07.301+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'scheduled__2024-10-01T15:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:17:08.223+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:17:08.305+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:17:08.306+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:17:08.312+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:17:08.331+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:17:08.392+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:17:08.401+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:17:08.417+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data scheduled__2024-10-01T15:05:00+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:17:08.849+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='scheduled__2024-10-01T15:05:00+00:00', try_number=2, map_index=-1)
[2024-10-01T18:17:08.851+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=scheduled__2024-10-01T15:05:00+00:00, map_index=-1, run_start_date=2024-10-01 15:17:08.441821+00:00, run_end_date=2024-10-01 15:17:08.510762+00:00, run_duration=0.068941, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:17:07.298821+00:00, queued_by_job_id=21, pid=16270
[2024-10-01T18:17:09.009+0300] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>
[2024-10-01T18:17:09.009+0300] {scheduler_job_runner.py:495} INFO - DAG mlopspmdl has 0/16 running and queued tasks
[2024-10-01T18:17:09.009+0300] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>
[2024-10-01T18:17:09.010+0300] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-10-01T18:17:09.010+0300] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:12:04.978301+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-10-01T18:17:09.010+0300] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:12:04.978301+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:17:09.012+0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'mlopspmdl', 'preprocess_data', 'manual__2024-10-01T15:12:04.978301+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_dag.py']
[2024-10-01T18:17:09.960+0300] {dagbag.py:588} INFO - Filling up the DagBag from /home/sofia/Документы/Symptom2Disease/services/airflow/dags/pipeline_dag.py
[2024-10-01T18:17:10.044+0300] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/sofia/Документы/Symptom2Disease/venv/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2024-10-01T18:17:10.045+0300] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:17:10.051+0300] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:17:10.070+0300] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2024-10-01T18:17:10.132+0300] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2024-10-01T18:17:10.140+0300] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2024-10-01T18:17:10.155+0300] {task_command.py:467} INFO - Running <TaskInstance: mlopspmdl.preprocess_data manual__2024-10-01T15:12:04.978301+00:00 [queued]> on host sofia-ASUS-TUF-Dash-F15-FX517ZC-FX517ZC
[2024-10-01T18:17:10.563+0300] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mlopspmdl', task_id='preprocess_data', run_id='manual__2024-10-01T15:12:04.978301+00:00', try_number=2, map_index=-1)
[2024-10-01T18:17:10.566+0300] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=mlopspmdl, task_id=preprocess_data, run_id=manual__2024-10-01T15:12:04.978301+00:00, map_index=-1, run_start_date=2024-10-01 15:17:10.180580+00:00, run_end_date=2024-10-01 15:17:10.250718+00:00, run_duration=0.070138, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-10-01 15:17:09.009774+00:00, queued_by_job_id=21, pid=16291
[2024-10-01T18:17:10.695+0300] {dagrun.py:823} ERROR - Marking run <DagRun mlopspmdl @ 2024-10-01 15:05:00+00:00: scheduled__2024-10-01T15:05:00+00:00, state:running, queued_at: 2024-10-01 15:12:05.638693+00:00. externally triggered: False> failed
Dag run  in failure state
Dag information:mlopspmdl Run id: scheduled__2024-10-01T15:05:00+00:00 external trigger: False
Failed with message: task_failure
[2024-10-01T18:17:10.695+0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=mlopspmdl, execution_date=2024-10-01 15:05:00+00:00, run_id=scheduled__2024-10-01T15:05:00+00:00, run_start_date=2024-10-01 15:12:05.649125+00:00, run_end_date=2024-10-01 15:17:10.695560+00:00, run_duration=305.046435, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-01 15:05:00+00:00, data_interval_end=2024-10-01 15:10:00+00:00, dag_hash=cdfac01871f4e4050b9a45083cfefadb
[2024-10-01T18:17:10.697+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:10:00+00:00, run_after=2024-10-01 15:15:00+00:00
[2024-10-01T18:17:11.837+0300] {dag.py:4180} INFO - Setting next_dagrun for mlopspmdl to 2024-10-01 15:15:00+00:00, run_after=2024-10-01 15:20:00+00:00
[2024-10-01T18:17:11.851+0300] {dagrun.py:823} ERROR - Marking run <DagRun mlopspmdl @ 2024-10-01 15:12:04.978301+00:00: manual__2024-10-01T15:12:04.978301+00:00, state:running, queued_at: 2024-10-01 15:12:04.995739+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:mlopspmdl Run id: manual__2024-10-01T15:12:04.978301+00:00 external trigger: True
Failed with message: task_failure
[2024-10-01T18:17:11.852+0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=mlopspmdl, execution_date=2024-10-01 15:12:04.978301+00:00, run_id=manual__2024-10-01T15:12:04.978301+00:00, run_start_date=2024-10-01 15:12:05.649258+00:00, run_end_date=2024-10-01 15:17:11.852068+00:00, run_duration=306.20281, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-10-01 15:05:00+00:00, data_interval_end=2024-10-01 15:10:00+00:00, dag_hash=cdfac01871f4e4050b9a45083cfefadb
[2024-10-01T18:18:58.197+0300] {scheduler_job_runner.py:260} INFO - Exiting gracefully upon receiving signal 15
[2024-10-01T18:18:59.207+0300] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 13082. PIDs of all processes in the group: [13082]
[2024-10-01T18:18:59.207+0300] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 13082
[2024-10-01T18:18:59.300+0300] {process_utils.py:80} INFO - Process psutil.Process(pid=13082, status='terminated', exitcode=0, started='18:00:38') (13082) terminated with exit code 0
[2024-10-01T18:18:59.306+0300] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 13082. PIDs of all processes in the group: []
[2024-10-01T18:18:59.306+0300] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 13082
[2024-10-01T18:18:59.306+0300] {process_utils.py:101} INFO - Sending the signal Signals.SIGTERM to process 13082 as process group is missing.
[2024-10-01T18:18:59.306+0300] {scheduler_job_runner.py:1014} INFO - Exited execute loop
