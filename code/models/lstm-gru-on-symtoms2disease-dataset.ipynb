{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5312008,"sourceType":"datasetVersion","datasetId":3087304}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-21T13:57:02.041435Z","iopub.execute_input":"2024-09-21T13:57:02.041769Z","iopub.status.idle":"2024-09-21T13:57:02.976098Z","shell.execute_reply.started":"2024-09-21T13:57:02.041740Z","shell.execute_reply":"2024-09-21T13:57:02.975037Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/symptom2disease/Symptom2Disease.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Import Necessary Libraries\nimport string\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport torch\nimport torch.nn as nn\nimport torchtext\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:02.978078Z","iopub.execute_input":"2024-09-21T13:57:02.978623Z","iopub.status.idle":"2024-09-21T13:57:09.620002Z","shell.execute_reply.started":"2024-09-21T13:57:02.978590Z","shell.execute_reply":"2024-09-21T13:57:09.619119Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:09.626130Z","iopub.execute_input":"2024-09-21T13:57:09.626460Z","iopub.status.idle":"2024-09-21T13:57:09.660293Z","shell.execute_reply.started":"2024-09-21T13:57:09.626428Z","shell.execute_reply":"2024-09-21T13:57:09.658826Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Reading the Dataset","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/symptom2disease/Symptom2Disease.csv\")\ndf.drop(\"Unnamed: 0\",inplace=True,axis=1)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:09.661614Z","iopub.execute_input":"2024-09-21T13:57:09.661941Z","iopub.status.idle":"2024-09-21T13:57:09.708294Z","shell.execute_reply.started":"2024-09-21T13:57:09.661912Z","shell.execute_reply":"2024-09-21T13:57:09.707287Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"          label                                               text\n0     Psoriasis  I have been experiencing a skin rash on my arm...\n1     Psoriasis  My skin has been peeling, especially on my kne...\n2     Psoriasis  I have been experiencing joint pain in my fing...\n3     Psoriasis  There is a silver like dusting on my skin, esp...\n4     Psoriasis  My nails have small dents or pits in them, and...\n...         ...                                                ...\n1195   diabetes  I'm shaking and trembling all over. I've lost ...\n1196   diabetes  Particularly in the crevices of my skin, I hav...\n1197   diabetes  I regularly experience these intense urges and...\n1198   diabetes  I have trouble breathing, especially outside. ...\n1199   diabetes  I constantly sneeze and have a dry cough. My i...\n\n[1200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Psoriasis</td>\n      <td>I have been experiencing a skin rash on my arm...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Psoriasis</td>\n      <td>My skin has been peeling, especially on my kne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Psoriasis</td>\n      <td>I have been experiencing joint pain in my fing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Psoriasis</td>\n      <td>There is a silver like dusting on my skin, esp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Psoriasis</td>\n      <td>My nails have small dents or pits in them, and...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>diabetes</td>\n      <td>I'm shaking and trembling all over. I've lost ...</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>diabetes</td>\n      <td>Particularly in the crevices of my skin, I hav...</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>diabetes</td>\n      <td>I regularly experience these intense urges and...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>diabetes</td>\n      <td>I have trouble breathing, especially outside. ...</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>diabetes</td>\n      <td>I constantly sneeze and have a dry cough. My i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing steps:stopwords removal,datacleaning etc","metadata":{}},{"cell_type":"code","source":"# set of English stopwords we will remove from our text data\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:09.709513Z","iopub.execute_input":"2024-09-21T13:57:09.709859Z","iopub.status.idle":"2024-09-21T13:57:09.719679Z","shell.execute_reply.started":"2024-09-21T13:57:09.709821Z","shell.execute_reply":"2024-09-21T13:57:09.718573Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def clean_text(sent):\n    #remove punctuations\n    sent = sent.translate(str.maketrans('','',string.punctuation)).strip()\n    \n    #remove stopwords\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(sent)\n    words = [word for word in words if word not in stop_words]\n    \n    return \" \".join(words).lower()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:09.721220Z","iopub.execute_input":"2024-09-21T13:57:09.721822Z","iopub.status.idle":"2024-09-21T13:57:09.728244Z","shell.execute_reply.started":"2024-09-21T13:57:09.721789Z","shell.execute_reply":"2024-09-21T13:57:09.727364Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# clean text rows in dataframe\ndf[\"text\"] = df[\"text\"].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:09.729552Z","iopub.execute_input":"2024-09-21T13:57:09.730092Z","iopub.status.idle":"2024-09-21T13:57:10.374873Z","shell.execute_reply.started":"2024-09-21T13:57:09.730061Z","shell.execute_reply":"2024-09-21T13:57:10.373922Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# get list of diseases in our dataset\ndiseases = df[\"label\"].unique()\n\n# helper dictionaries to convert diseases to index and vice versa\nidx2dis = {k:v for k,v in enumerate(diseases)}\ndis2idx = {v:k for k,v in idx2dis.items()}","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.376433Z","iopub.execute_input":"2024-09-21T13:57:10.376791Z","iopub.status.idle":"2024-09-21T13:57:10.385229Z","shell.execute_reply.started":"2024-09-21T13:57:10.376760Z","shell.execute_reply":"2024-09-21T13:57:10.384151Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# convert disease name to index (label encoding)\ndf[\"label\"] = df[\"label\"].apply(lambda x: dis2idx[x])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.389716Z","iopub.execute_input":"2024-09-21T13:57:10.390056Z","iopub.status.idle":"2024-09-21T13:57:10.400444Z","shell.execute_reply.started":"2024-09-21T13:57:10.390025Z","shell.execute_reply":"2024-09-21T13:57:10.399469Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Split the data into train,test set\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.401530Z","iopub.execute_input":"2024-09-21T13:57:10.401842Z","iopub.status.idle":"2024-09-21T13:57:10.415097Z","shell.execute_reply.started":"2024-09-21T13:57:10.401814Z","shell.execute_reply":"2024-09-21T13:57:10.414133Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# pytorch dataset object use index to return item, so need to reset non-continuoues index of divided dataset\nX_train.reset_index(drop=True, inplace=True)\nX_test.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.416381Z","iopub.execute_input":"2024-09-21T13:57:10.416721Z","iopub.status.idle":"2024-09-21T13:57:10.422000Z","shell.execute_reply.started":"2024-09-21T13:57:10.416692Z","shell.execute_reply":"2024-09-21T13:57:10.420966Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# max number of words in symptoms descriptions (cleaned version)\nmax_words = X_train.apply(lambda x:x.split()).apply(len).max()\nmax_words","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.423734Z","iopub.execute_input":"2024-09-21T13:57:10.424109Z","iopub.status.idle":"2024-09-21T13:57:10.441419Z","shell.execute_reply.started":"2024-09-21T13:57:10.424067Z","shell.execute_reply":"2024-09-21T13:57:10.440336Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"# create vocabulart using torchtext vocab class\ncounter = Counter()\nfor text in X_train:\n    counter.update(text.split())\n\nvocab = torchtext.vocab.vocab(counter,specials=['<unk>', '<pad>'])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.442835Z","iopub.execute_input":"2024-09-21T13:57:10.443297Z","iopub.status.idle":"2024-09-21T13:57:10.542842Z","shell.execute_reply.started":"2024-09-21T13:57:10.443236Z","shell.execute_reply":"2024-09-21T13:57:10.541806Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# set default index as unknown token\nvocab.set_default_index(vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.544168Z","iopub.execute_input":"2024-09-21T13:57:10.544533Z","iopub.status.idle":"2024-09-21T13:57:10.553793Z","shell.execute_reply.started":"2024-09-21T13:57:10.544488Z","shell.execute_reply":"2024-09-21T13:57:10.552805Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create a PyTorch dataset`\nclass DiseaseDataset(torch.utils.data.Dataset):\n    def __init__(self, symptoms,labels):\n        self.symptoms = symptoms\n        self.labels= torch.tensor(labels.to_numpy())\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        text = self.symptoms[idx]\n        label = self.labels[idx]\n\n        # Convert the text to a sequence of word indices\n        text_indices = [vocab[word] for word in text.split()]\n        \n        # padding for same length sequence\n        if len(text_indices)<max_words:\n            text_indices = text_indices + [1]*(max_words - len(text_indices))\n        \n        return torch.tensor(text_indices), label","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.555156Z","iopub.execute_input":"2024-09-21T13:57:10.555512Z","iopub.status.idle":"2024-09-21T13:57:10.564266Z","shell.execute_reply.started":"2024-09-21T13:57:10.555479Z","shell.execute_reply":"2024-09-21T13:57:10.563173Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# instantiate dataset objects\ntrain_dataset = DiseaseDataset(X_train, y_train)\nval_dataset = DiseaseDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.565462Z","iopub.execute_input":"2024-09-21T13:57:10.565795Z","iopub.status.idle":"2024-09-21T13:57:10.597048Z","shell.execute_reply.started":"2024-09-21T13:57:10.565763Z","shell.execute_reply":"2024-09-21T13:57:10.596252Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# choose batch size, will start from smaller values as we got smaller dataset\nbatch_size = 8\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.598142Z","iopub.execute_input":"2024-09-21T13:57:10.598927Z","iopub.status.idle":"2024-09-21T13:57:10.605908Z","shell.execute_reply.started":"2024-09-21T13:57:10.598893Z","shell.execute_reply":"2024-09-21T13:57:10.604859Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define the RNN model\nclass RNNModel(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim,num_classes,drop_prob,num_layers=1,bidir=False,seq=\"lstm\"):\n        super(RNNModel, self).__init__()\n        self.seq = seq\n        self.bidir_f = 2 if bidir else 0\n        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n        if seq==\"lstm\":\n            self.rnn = torch.nn.LSTM(embedding_dim, hidden_dim,\n                                     num_layers=num_layers,\n                                     batch_first=True,\n                                     bidirectional=bidir)\n        else:\n            self.rnn = torch.nn.GRU(embedding_dim, hidden_dim,\n                                 num_layers=num_layers,\n                                 batch_first=True,\n                                bidirectional=bidir)\n        \n        self.dropout = torch.nn.Dropout(drop_prob) #dropout layer\n        self.fc = torch.nn.Linear(hidden_dim*self.bidir_f, num_classes) # fully connected layer\n\n    def forward(self, text_indices):\n        # Embed the text indices\n        embedded_text = self.embedding(text_indices)\n#         print(\"EMB SHAPE: \",embedded_text.shape)\n\n        # Pass the embedded text through the RNN\n        rnn_output,hidden_states = self.rnn(embedded_text)\n        # Take the last output of the RNN\n        last_rnn_output = rnn_output[:, -1, :]\n        x = self.dropout(last_rnn_output)\n        # Pass the last output of the RNN through the fully connected layer\n        x = self.fc(x)\n\n        # Return the final output\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.606925Z","iopub.execute_input":"2024-09-21T13:57:10.609537Z","iopub.status.idle":"2024-09-21T13:57:10.620108Z","shell.execute_reply.started":"2024-09-21T13:57:10.609502Z","shell.execute_reply":"2024-09-21T13:57:10.619280Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train(model,num_epochs=10):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    \n    #choose device for training\n    device = \"cuda\" if torch.cuda.is_available()  else \"cpu\"\n    model = model.cuda()\n    model = model.to(device)\n    print(\"IS CUDA: \",next(model.parameters()).is_cuda)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        model.train()\n        for data in train_loader:\n            inputs,labels = data \n            inputs,labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            acc = (labels == outputs.argmax(dim=-1)).float().mean().item()\n            loss.backward()\n            optimizer.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0.0\n            correct = 0\n            total = 0\n            for inputs, labels in val_loader:\n                inputs,labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                predicted = outputs.argmax(-1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        accuracy = (labels == outputs.argmax(dim=-1)).float().mean().item()\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {val_loss}, Train Accuracy: {acc:.2f}  Val Accuracy: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.621371Z","iopub.execute_input":"2024-09-21T13:57:10.621772Z","iopub.status.idle":"2024-09-21T13:57:10.636282Z","shell.execute_reply.started":"2024-09-21T13:57:10.621744Z","shell.execute_reply":"2024-09-21T13:57:10.635320Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_classes = len(np.unique(y_train))\nvocab_size = len(vocab)\nemb_dim = 256\nhidden_dim = 128\ndrop_prob = 0.4","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.637753Z","iopub.execute_input":"2024-09-21T13:57:10.638102Z","iopub.status.idle":"2024-09-21T13:57:10.649185Z","shell.execute_reply.started":"2024-09-21T13:57:10.638073Z","shell.execute_reply":"2024-09-21T13:57:10.648214Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_lstm = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=3,bidir=True, seq=\"lstm\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.650763Z","iopub.execute_input":"2024-09-21T13:57:10.651092Z","iopub.status.idle":"2024-09-21T13:57:10.689396Z","shell.execute_reply.started":"2024-09-21T13:57:10.651065Z","shell.execute_reply":"2024-09-21T13:57:10.688553Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model_lstm,35)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:10.690416Z","iopub.execute_input":"2024-09-21T13:57:10.690726Z","iopub.status.idle":"2024-09-21T13:57:35.473493Z","shell.execute_reply.started":"2024-09-21T13:57:10.690694Z","shell.execute_reply":"2024-09-21T13:57:35.472553Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"IS CUDA:  True\nEpoch [1/35], Loss: 92.01725339889526, Train Accuracy: 0.00  Val Accuracy: 0.00\nEpoch [2/35], Loss: 78.9551649093628, Train Accuracy: 0.00  Val Accuracy: 0.00\nEpoch [3/35], Loss: 74.6918408870697, Train Accuracy: 0.12  Val Accuracy: 0.12\nEpoch [4/35], Loss: 61.21231651306152, Train Accuracy: 0.25  Val Accuracy: 0.25\nEpoch [5/35], Loss: 50.374439120292664, Train Accuracy: 0.38  Val Accuracy: 0.62\nEpoch [6/35], Loss: 32.70776554942131, Train Accuracy: 0.75  Val Accuracy: 0.88\nEpoch [7/35], Loss: 29.302746415138245, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [8/35], Loss: 28.719481825828552, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [9/35], Loss: 26.834640324115753, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [10/35], Loss: 23.35372630134225, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [11/35], Loss: 25.242680657655, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [12/35], Loss: 23.69400708936155, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [13/35], Loss: 34.005266319960356, Train Accuracy: 0.75  Val Accuracy: 0.62\nEpoch [14/35], Loss: 29.018865330144763, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [15/35], Loss: 27.532732857391238, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [16/35], Loss: 29.69254532456398, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [17/35], Loss: 28.506075870245695, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [18/35], Loss: 29.304823752958328, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [19/35], Loss: 29.40907395351678, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [20/35], Loss: 28.73784333257936, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [21/35], Loss: 29.555528026307, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [22/35], Loss: 30.73485639737919, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [23/35], Loss: 31.014089353382587, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [24/35], Loss: 31.393701104447246, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [25/35], Loss: 31.366378720616922, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [26/35], Loss: 32.21929696551524, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [27/35], Loss: 32.04369915497955, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [28/35], Loss: 32.174819232546724, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [29/35], Loss: 32.96258625504561, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [30/35], Loss: 32.66090060828719, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [31/35], Loss: 33.148885876638815, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [32/35], Loss: 33.842523680534214, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [33/35], Loss: 34.19772488612216, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [34/35], Loss: 33.713942315313034, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [35/35], Loss: 34.15509883768391, Train Accuracy: 1.00  Val Accuracy: 0.88\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gru = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=1,bidir=True,seq=\"gru\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:35.474787Z","iopub.execute_input":"2024-09-21T13:57:35.475409Z","iopub.status.idle":"2024-09-21T13:57:35.489703Z","shell.execute_reply.started":"2024-09-21T13:57:35.475372Z","shell.execute_reply":"2024-09-21T13:57:35.488962Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train(model_gru,20)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:35.490714Z","iopub.execute_input":"2024-09-21T13:57:35.491009Z","iopub.status.idle":"2024-09-21T13:57:43.131894Z","shell.execute_reply.started":"2024-09-21T13:57:35.490979Z","shell.execute_reply":"2024-09-21T13:57:43.131018Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"IS CUDA:  True\nEpoch [1/20], Loss: 88.82546520233154, Train Accuracy: 0.00  Val Accuracy: 0.25\nEpoch [2/20], Loss: 61.91657745838165, Train Accuracy: 0.38  Val Accuracy: 0.62\nEpoch [3/20], Loss: 36.18146961927414, Train Accuracy: 0.62  Val Accuracy: 0.88\nEpoch [4/20], Loss: 22.785705775022507, Train Accuracy: 0.88  Val Accuracy: 1.00\nEpoch [5/20], Loss: 16.199264124035835, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [6/20], Loss: 12.187511496245861, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [7/20], Loss: 11.177432298660278, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [8/20], Loss: 9.949819948524237, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [9/20], Loss: 8.938183657824993, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [10/20], Loss: 8.670395903289318, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [11/20], Loss: 8.942874561995268, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [12/20], Loss: 8.719596456736326, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [13/20], Loss: 8.624773809686303, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [14/20], Loss: 8.123713795095682, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [15/20], Loss: 8.347861812449992, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [16/20], Loss: 8.221004098188132, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [17/20], Loss: 8.612927931826562, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [18/20], Loss: 8.383127857465297, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [19/20], Loss: 8.737326659727842, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [20/20], Loss: 8.898844430223107, Train Accuracy: 1.00  Val Accuracy: 1.00\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_pred(model,text):\n    text = clean_text(text)\n    # Convert the text to a sequence of word indices\n    text_indices = [vocab[word] for word in text.split()]\n        \n    # padding for same length sequence\n    if len(text_indices)<max_words:\n        text_indices = text_indices + [1]*(max_words - len(text_indices))\n    text_indices = torch.tensor(text_indices).cuda()\n    pred = model(text_indices.unsqueeze(0))\n\n    print(idx2dis[pred.argmax(1).item()])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:57:43.133104Z","iopub.execute_input":"2024-09-21T13:57:43.133470Z","iopub.status.idle":"2024-09-21T13:57:43.139754Z","shell.execute_reply.started":"2024-09-21T13:57:43.133438Z","shell.execute_reply":"2024-09-21T13:57:43.138758Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"symp2 = \"I've been itching a lot\"\n\nmake_pred(model_lstm, symp2)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:59:07.448415Z","iopub.execute_input":"2024-09-21T13:59:07.449316Z","iopub.status.idle":"2024-09-21T13:59:07.457263Z","shell.execute_reply.started":"2024-09-21T13:59:07.449282Z","shell.execute_reply":"2024-09-21T13:59:07.456345Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Varicose Veins\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model_lstm.state_dict(), \"/kaggle/working/model_lstm.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T14:26:54.535909Z","iopub.execute_input":"2024-09-21T14:26:54.536741Z","iopub.status.idle":"2024-09-21T14:26:54.555910Z","shell.execute_reply.started":"2024-09-21T14:26:54.536706Z","shell.execute_reply":"2024-09-21T14:26:54.555169Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"mdl = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=3,bidir=True, seq=\"lstm\")\nmdl.load_state_dict(torch.load(\"/kaggle/working/model_lstm.h5\", weights_only=True))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T14:30:51.701204Z","iopub.execute_input":"2024-09-21T14:30:51.701890Z","iopub.status.idle":"2024-09-21T14:30:51.735615Z","shell.execute_reply.started":"2024-09-21T14:30:51.701857Z","shell.execute_reply":"2024-09-21T14:30:51.734741Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"make_pred(mdl.cuda(), \"my stomach ache\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T14:33:22.971783Z","iopub.execute_input":"2024-09-21T14:33:22.972491Z","iopub.status.idle":"2024-09-21T14:33:22.982140Z","shell.execute_reply.started":"2024-09-21T14:33:22.972459Z","shell.execute_reply":"2024-09-21T14:33:22.981187Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"peptic ulcer disease\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}